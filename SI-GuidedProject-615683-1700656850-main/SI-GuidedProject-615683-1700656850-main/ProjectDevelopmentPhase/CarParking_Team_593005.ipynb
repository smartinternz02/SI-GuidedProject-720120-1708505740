{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ZN8UyRXoyN",
        "outputId": "68cc7f53-21f4-460c-8cd5-896a18e401ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeZAYym1XmQh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files(directory):\n",
        "    return sum([len(files) for _, _, files in os.walk(directory)])\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/AI_Enabled_Car_Parking/CarParking_Dataset/train_data/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/AI_Enabled_Car_Parking/CarParking_Dataset/train_data/test'\n",
        "\n",
        "files_train = count_files(train_data_dir)\n",
        "files_validation = count_files(validation_data_dir)\n",
        "\n",
        "print(files_train, files_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42dXoIk4XrB6",
        "outputId": "ddafb09f-2fb9-448e-885c-1a2ff681d081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381 164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "img_width, img_height = 128, 128\n",
        "train_data_dir = \"/content/drive/MyDrive/AI_Enabled_Car_Parking/CarParking_Dataset/train_data/train\"\n",
        "validation_data_dir = \"/content/drive/MyDrive/AI_Enabled_Car_Parking/CarParking_Dataset/train_data/test\"\n",
        "nb_train_samples = files_train\n",
        "nb_validation_samples = files_validation\n",
        "batch_size = 32\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "tT0Vp919X0sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained VGG16 model\n",
        "base_model = applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Freezing layers in the base model\n",
        "for layer in base_model.layers[:10]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlZNJJCAX5Sa",
        "outputId": "ac03a595-4d17-4d18-fee6-d32d08798c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding custom dense layer for binary classification\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(units=2, activation='softmax')(x)\n",
        "model = Model(base_model.input, x)"
      ],
      "metadata": {
        "id": "UmVnF5MBX_Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Z8LLyHYNmg",
        "outputId": "4008c688-83ee-48f0-e2e0-4c93a93fc75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14715714 (56.14 MB)\n",
            "Trainable params: 12980226 (49.52 MB)\n",
            "Non-trainable params: 1735488 (6.62 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7NrAcTKTYCi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    rotation_range=5)\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\",\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    rotation_range=5)\n"
      ],
      "metadata": {
        "id": "MPoePTA9YFQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q0O5DtEYVAt",
        "outputId": "9a23e9c4-4987-479c-93a9-d4f8706b631a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 381 images belonging to 2 classes.\n",
            "Found 164 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "checkpoint = ModelCheckpoint(\"car1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "history_object = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint, early])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqtWdqw3YV1l",
        "outputId": "33cf8ed6-d13d-4dea-f52e-c05a88e91007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-11-c9c9e40c8e87>:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history_object = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.7402 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 233s 20s/step - loss: 0.4304 - accuracy: 0.7402 - val_loss: 0.2763 - val_accuracy: 0.8780\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9475 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 168s 14s/step - loss: 0.1864 - accuracy: 0.9475 - val_loss: 0.7644 - val_accuracy: 0.8476\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9475 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 178s 15s/step - loss: 0.1705 - accuracy: 0.9475 - val_loss: 0.2663 - val_accuracy: 0.9268\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9685 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 177s 15s/step - loss: 0.0890 - accuracy: 0.9685 - val_loss: 0.2307 - val_accuracy: 0.9207\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9816 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/12 [==============================] - 167s 14s/step - loss: 0.0781 - accuracy: 0.9816 - val_loss: 0.3581 - val_accuracy: 0.8902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model prediction function\n",
        "def prediction(path):\n",
        "    img = tf.keras.preprocessing.image.load_img(path, target_size=(img_height, img_width))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Rescaling\n",
        "    pred = np.argmax(model.predict(img_array))\n",
        "    print(f\"The image belongs to class {pred}\")"
      ],
      "metadata": {
        "id": "rjHSSvLwYYTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction\n",
        "image_path = \"/content/drive/MyDrive/AI_Enabled_Car_Parking/CarParking_Dataset/test_images/scene1410.jpg\"\n",
        "prediction(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8X-maFjYcyJ",
        "outputId": "ab71a752-5adb-44f9-c2fa-3ce27ee0eb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 550ms/step\n",
            "The image belongs to class 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as a pickle file\n",
        "import pickle\n",
        "\n",
        "model_dict = {'model': model.to_json(), 'weights': model.get_weights()}\n",
        "\n",
        "with open('/content/drive/MyDrive/AI_Enabled_Car_Parking/spot_dict.pickle', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)"
      ],
      "metadata": {
        "id": "-4yn8ZfYYiAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}